{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# A notebook which duplicate most part of the study done in Scavager manuscript.\n",
    "# Please contact me at markmipt@gmail.com with any questions and bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyteomics import pepxml, auxiliary as aux, fasta, achrom, mass, electrochem as ec, parser, mgf, mass, cmass, mzid, protxml\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "from os import path, listdir, mkdir\n",
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "from matplotlib.patches import Patch\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to study. If folder does not exist it will be created\n",
    "infolder = '/home/mark/overfit_test/'\n",
    "if not path.isdir(infolder):\n",
    "    mkdir(infolder)\n",
    "    \n",
    "#Set path to folder where fasta files for study will be stored\n",
    "fasta_folder = path.join(infolder, 'fasta')\n",
    "if not path.isdir(fasta_folder):\n",
    "    mkdir(fasta_folder)\n",
    "    \n",
    "#Please, put target fasta file to fasta folder and write filename below\n",
    "path_to_input_target_fasta = path.join(fasta_folder, 'sprot_human.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for shuffle DECOY database generation. Reduce intersection of target and decoy peptides to minimum.\n",
    "\n",
    "def make_shuffle_new(infile, prefix='DECOY_', expasy_r=parser.expasy_rules['trypsin']):\n",
    "    \n",
    "    defaalist = set(mass.std_aa_mass.keys())\n",
    "    defaalist.remove('O')\n",
    "    defaalist.remove('U')\n",
    "    defaalist.remove('R')\n",
    "    defaalist.remove('K')\n",
    "    defaalist = list(defaalist)\n",
    "    \n",
    "    cnt_shared = 0\n",
    "    cnt_defshared = 0\n",
    "    prots = []\n",
    "    all_peps = set()\n",
    "    for p in fasta.read(infile):\n",
    "        rseq = p[1].replace('L', 'I')\n",
    "        peps = parser.cleave(rseq, expasy_r, 2, min_length=6)\n",
    "        all_peps.update(peps)\n",
    "        prots.append((p[0], rseq))\n",
    "        \n",
    "    for p in fasta.read(infile):\n",
    "        sh_seq = fasta.shuffle(p[1].replace('L', 'I'), keep_nterm=True)\n",
    "        peps = parser.cleave(sh_seq, expasy_r, 2, min_length=6)\n",
    "        for pep in peps:\n",
    "            if pep in all_peps:\n",
    "                cnt_defshared += 1\n",
    "                i = 30\n",
    "                flag = 1\n",
    "                while i > 0:\n",
    "                    npep = fasta.shuffle(pep, keep_cterm=True, keep_nterm=False)\n",
    "                    if npep not in all_peps:\n",
    "                        flag = 0\n",
    "                        break\n",
    "                    else:\n",
    "                        i -= 1\n",
    "                        \n",
    "\n",
    "                i = 30\n",
    "                while i > 0:\n",
    "                    N = len(pep) - 1\n",
    "                    npep = ''.join(random.choice(defaalist) for _ in range(N)) + pep[-1]\n",
    "                    if npep not in all_peps:\n",
    "                        flag = 0\n",
    "                        break\n",
    "                    else:\n",
    "                        i -= 1\n",
    "                        \n",
    "                        \n",
    "                if flag:\n",
    "                    cnt_shared += 1\n",
    "                sh_seq = sh_seq.replace(pep, npep)\n",
    "        prots.append((prefix + p[0], sh_seq))\n",
    "    print(cnt_shared)\n",
    "    print(cnt_defshared)\n",
    "    return prots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE 9 FASTA FILES using double shuffling. Details can be found in the manuscript.\n",
    "\n",
    "infile = path_to_input_target_fasta\n",
    "i = 1\n",
    "while i <= 9:\n",
    "    tmpfile = infile.split('.fasta')[0] + '_shuffled_CHECK_%d.fasta' % (i, )\n",
    "    outfile = infile.split('.fasta')[0] + '_shuffled_DECOY_%d.fasta' % (i, )\n",
    "    prots1 = make_shuffle_new(infile, prefix='CHECK_')\n",
    "    fasta.write(prots1, output=open(tmpfile, 'w')).close()\n",
    "    prots2 = make_shuffle_new(tmpfile, prefix='DECOY_')\n",
    "    fasta.write(prots2, output=open(outfile, 'w')).close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of theoretical tryptic peptides\n",
    "path_to_any_decoy_fasta = path_to_input_target_fasta.split('.fasta')[0] + '_shuffled_DECOY_1.fasta'\n",
    "all_peps = set()\n",
    "for p in fasta.read(path_to_any_decoy_fasta):\n",
    "    all_peps.update(parser.cleave(p[1], parser.expasy_rules['trypsin'], 2, min_length=6))\n",
    "print(len(all_peps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path to folder with spectra files. We have used in the study only mzML files\n",
    "mgf_folder = path.join(infolder, 'mzml')\n",
    "if not path.isdir(mgf_folder):\n",
    "    mkdir(mgf_folder)\n",
    "    \n",
    "#Please, put spectra files to spectra folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN MSFragger\n",
    "\n",
    "# MSFragger require file with parameters. It will be automatically taken from the parameters folder,\n",
    "# but it should be in format name_of_spectra_file.params\n",
    "# Path to fasta file inside the parameters will be replaced here in the script automatically\n",
    "\n",
    "msfragger_folder = path.join(infolder, 'msfragger')\n",
    "if not path.isdir(msfragger_folder):\n",
    "    mkdir(msfragger_folder)\n",
    "msfragger_params_folder = path.join(infolder, 'params')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    if mgffile.endswith('.mzML'):\n",
    "        basic_name = path.splitext(mgffile)[0]\n",
    "        inmgf = path.join(mgf_folder, mgffile)\n",
    "        print(inmgf)\n",
    "        msfragger_params_file = path.join(msfragger_params_folder, basic_name + '_fragger.params')\n",
    "        print(msfragger_params_file)\n",
    "        for fastafile in listdir(fasta_folder):\n",
    "            if '_DECOY_' in fastafile and fastafile.endswith('.fasta'):\n",
    "                fpath = path.join(fasta_folder, fastafile)\n",
    "                search_number = fastafile.split('.fasta')[0].split('_')[-1]\n",
    "                \n",
    "                \n",
    "                tmp_fragger_params = path.join(msfragger_params_folder, 'tmp_fragger.params')\n",
    "                file_writer = open(tmp_fragger_params, 'w')\n",
    "                for line in open(msfragger_params_file):\n",
    "                    if line.startswith('database_name'):\n",
    "                        line = 'database_name = %s\\n' % (fpath, )\n",
    "                    file_writer.write(line)\n",
    "                file_writer.close()\n",
    "                !MSFragger $tmp_fragger_params $inmgf\n",
    "                pepxml_name = path.join(mgf_folder, basic_name + '.pepXML')\n",
    "                pepxml_name_new = path.join(msfragger_folder, basic_name + '_%s.pep.xml' % (search_number, ))\n",
    "                shutil.move(pepxml_name, pepxml_name_new)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN X!Tandem\n",
    "\n",
    "# X!Tandem require file with parameters. It will be automatically taken from the parameters folder,\n",
    "# but it should be in format name_of_spectra_file.xml\n",
    "\n",
    "xtandem_folder = path.join(infolder, 'xtandem')\n",
    "if not path.isdir(xtandem_folder):\n",
    "    mkdir(xtandem_folder)\n",
    "xtandem_params_folder = path.join(infolder, 'params')\n",
    "path_to_tandem_exe = 'tandem.exe'\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    if mgffile.endswith('.mzML'):\n",
    "        basic_name = path.splitext(mgffile)[0]\n",
    "        inmgf = path.join(mgf_folder, mgffile)\n",
    "        print(inmgf)\n",
    "        xtandem_params_file = path.join(xtandem_params_folder, basic_name + '.xml')\n",
    "        print(xtandem_params_file)\n",
    "        if not path.isdir(xtandem_folder):\n",
    "            mkdir(xtandem_folder)\n",
    "        for fastafile in listdir(fasta_folder):\n",
    "            if '_DECOY_' in fastafile and fastafile.endswith('.fasta'):\n",
    "                fpath = path.join(fasta_folder, fastafile)\n",
    "                search_number = fastafile.split('.fasta')[0].split('_')[-1]\n",
    "                !runtandem --tandem2xml pepxmltk.py --tandem.exe $path_to_tandem_exe $xtandem_params_file $xtandem_folder $fpath $inmgf\n",
    "                pepxml_name = path.join(xtandem_folder, basic_name + '.pep.xml')\n",
    "                pepxml_name_new = pepxml_name.replace('.pep.xml', '_%s.pep.xml' % (search_number, ))\n",
    "                txml_name = path.join(xtandem_folder, basic_name + '.t.xml')\n",
    "                txml_name_new = txml_name.replace('.t.xml', '_%s.t.xml' % (search_number, ))\n",
    "                shutil.move(pepxml_name, pepxml_name_new)\n",
    "                shutil.move(txml_name, txml_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN msgf+\n",
    "\n",
    "# msgf+ require file with modifications. Please, put msgf_mods.txt file to folder with parameters.\n",
    "\n",
    "msgf_folder = path.join(infolder, 'msgf_mzml')\n",
    "if not path.isdir(msgf_folder):\n",
    "    mkdir(msgf_folder)\n",
    "mzml_folder = path.join(infolder, 'mzml')\n",
    "\n",
    "for mgffile in listdir(mzml_folder):\n",
    "    if mgffile.endswith('.mzML'):\n",
    "        basic_name = path.splitext(mgffile)[0]\n",
    "\n",
    "        if 'confetti' in basic_name:\n",
    "            inst_type = 0\n",
    "            mods_file = path.join(infolder, 'params/msgf_mods_confetti.txt')\n",
    "        else:\n",
    "            inst_type = 3\n",
    "            mods_file = path.join(infolder, 'params/msgf_mods.txt')\n",
    "        if '20100609' in basic_name:\n",
    "            ppmacc = '20ppm'\n",
    "        else:\n",
    "            ppmacc = '10ppm'\n",
    "\n",
    "        inmgf = path.join(mzml_folder, mgffile)\n",
    "        print(inmgf)\n",
    "        for fastafile in listdir(fasta_folder):\n",
    "            if '_DECOY_' in fastafile and fastafile.endswith('.fasta'):\n",
    "                fpath = path.join(fasta_folder, fastafile)\n",
    "                search_number = fastafile.split('.fasta')[0].split('_')[-1]\n",
    "                fileroot = basic_name + '_' + search_number\n",
    "                mzid_name = path.join(msgf_folder, basic_name + '_%s.mzid' % (search_number, ))\n",
    "                !msgf+ -s $inmgf -d $fpath -o $mzid_name -t $ppmacc -addFeatures 1 -inst $inst_type -mod $mods_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN comet\n",
    "comet_folder = path.join(infolder, 'comet')\n",
    "if not path.isdir(comet_folder):\n",
    "    mkdir(comet_folder)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    if mgffile.endswith('.mzML'):\n",
    "        basic_name = path.splitext(mgffile)[0]\n",
    "\n",
    "        if 'confetti' in basic_name:\n",
    "            cys_fixed_mod = 125.047679\n",
    "            frag_bin_tol = 0.3\n",
    "        else:\n",
    "            cys_fixed_mod = 57.021464\n",
    "            frag_bin_tol = 0.05\n",
    "        if '20100609' in basic_name:\n",
    "            ppmacc = 20.0\n",
    "        else:\n",
    "            ppmacc = 10.0\n",
    "            \n",
    "        inmgf = path.join(mgf_folder, mgffile)\n",
    "        print(inmgf)\n",
    "        for fastafile in listdir(fasta_folder):\n",
    "            if '_DECOY_' in fastafile and fastafile.endswith('.fasta'):\n",
    "                fpath = path.join(fasta_folder, fastafile)\n",
    "                search_number = fastafile.split('.fasta')[0].split('_')[-1]\n",
    "                fileroot = basic_name + '_' + search_number\n",
    "                !crux comet $inmgf $fpath --peptide_mass_tolerance $ppmacc --peptide_mass_units 2 \\\n",
    "                            --fragment_bin_tol $frag_bin_tol --output-dir $comet_folder --add_C_cysteine $cys_fixed_mod \\\n",
    "                            --fileroot $fileroot --num_output_lines 1 --isotope_error 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Identipy\n",
    "identipy_folder = path.join(infolder, 'identipy')\n",
    "if not path.isdir(identipy_folder):\n",
    "    mkdir(identipy_folder)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    if mgffile.endswith('.mzML'):\n",
    "        \n",
    "        basic_name = path.splitext(mgffile)[0]\n",
    "        inmgf = path.join(mgf_folder, mgffile)\n",
    "        \n",
    "        if 'confetti' in basic_name:\n",
    "            cys_fixed_mod = '125.047679@C'\n",
    "            frag_bin_tol = 0.3\n",
    "        else:\n",
    "            cys_fixed_mod = '57.021464@C'\n",
    "            frag_bin_tol = 0.05\n",
    "        if '20100609' in basic_name:\n",
    "            ppmacc = 20.0\n",
    "        else:\n",
    "            ppmacc = 10.0\n",
    "        \n",
    "        print(inmgf)\n",
    "        for fastafile in listdir(fasta_folder):\n",
    "            if '_DECOY_' in fastafile and fastafile.endswith('.fasta'):\n",
    "                fpath = path.join(fasta_folder, fastafile)\n",
    "                search_number = fastafile.split('.fasta')[0].split('_')[-1]\n",
    "                \n",
    "                \n",
    "                !identipy $inmgf -db $fpath\\\n",
    "                -punit ppm -ptol $ppmacc -funit Da -ftol $frag_bin_tol -fminmz 100 -lmin 6 -lmax 60 -massmin 200\\\n",
    "                -massmax 10000 -mc 2 -cmin 1 -prefix DECOY_ -deistol $frag_bin_tol -cmax 9\\\n",
    "                -fmods $cys_fixed_mod -at yes -ime 1\n",
    "                \n",
    "                pepxml_name = path.join(mgf_folder, basic_name + '.pep.xml')\n",
    "    \n",
    "                pepxml_name_new = path.join(identipy_folder, basic_name + '.pep.xml').replace('.pep.xml', '_%s.pep.xml' % (search_number, ))\n",
    "                shutil.move(pepxml_name, pepxml_name_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Scavager for all search engines results\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "for ffolder in [\n",
    "    msfragger_folder,\n",
    "    xtandem_folder,\n",
    "    identipy_folder,\n",
    "    comet_folder,\n",
    "    msgf_folder\n",
    "]:\n",
    "    for z in listdir(ffolder):\n",
    "        if z.endswith('.pep.xml') or z.endswith('.mzid'):\n",
    "            intf = path.join(ffolder, z)\n",
    "            !scavager $intf -prefix $decoy_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Peptide/ProteinProphet for all search engines results\n",
    "\n",
    "# Please, convert msgf .mzid files to .pepXML format using idconvert.exe from ProteoWizard\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "fasta_template = path_to_input_target_fasta.split('.fasta')[0] + '_shuffled_DECOY_%s.fasta'\n",
    "\n",
    "!philosopher workspace --init\n",
    "\n",
    "for ffolder in [\n",
    "    msfragger_folder,\n",
    "    xtandem_folder,\n",
    "    comet_folder,\n",
    "    msgf_folder\n",
    "]:\n",
    "    for z in listdir(ffolder):\n",
    "        if (z.endswith('.pep.xml') or z.endswith('.pepXML')) and not z.startswith('interact'):\n",
    "\n",
    "            basenum = z.split('.')[0].split('_')[-1]\n",
    "            infasta = fasta_template % (basenum, )\n",
    "            \n",
    "            intf = path.join(ffolder, z)\n",
    "#             !philosopher peptideprophet --accmass\\\n",
    "#             --database $infasta\\\n",
    "#             --decoy DECOY_ --decoyprobs --enzyme Trypsin --minpeplen 6 --expectscore $intf\n",
    "            \n",
    "            pepprophet_file = path.join(ffolder, 'interact-' + z)\n",
    "#             protprophet_file = path.join(ffolder, 'interact-' + z.replace('.pep.xml', '').replace('.pepXML', ''))\n",
    "            protprophet_file = 'interact-' + z.replace('.pep.xml', '').replace('.pepXML', '')\n",
    "            !philosopher proteinprophet $pepprophet_file --output $protprophet_file --nooccam\n",
    "            protprophet_file = protprophet_file + '.prot.xml'\n",
    "            shutil.move(protprophet_file, path.join(ffolder, protprophet_file))\n",
    "            \n",
    "#             !echo proteinprophet $pepprophet_file --output $protprophet_file --nooccam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for msgf+ results\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "for z in listdir(msgf_folder):\n",
    "    if z.endswith('.mzid'):\n",
    "        intf = path.join(msgf_folder, z)\n",
    "        outpin = path.join(msgf_folder, z.replace('.mzid', '.pin'))\n",
    "        !msgf2pin $intf -P $decoy_prefix -o $outpin\n",
    "        outtarget = path.join(msgf_folder, z.replace('.mzid', '.target'))\n",
    "        outdecoy = path.join(msgf_folder, z.replace('.mzid', '.decoy'))\n",
    "        !percolator $outpin -U -m $outtarget -M $outdecoy\n",
    "        \n",
    "        outtarget2 = outtarget.replace('.target', '.target2')\n",
    "        out = open(outtarget2, 'w')\n",
    "        for x in open(outtarget):\n",
    "            out.write('\\t'.join(x.split('\\t')[:5]) + '\\t' + ';'.join(x.split('\\t')[5:]) + '\\n')\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for X!Tandem output\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "for z in listdir(xtandem_folder):\n",
    "    if z.endswith('.t.xml'):\n",
    "        intf = path.join(xtandem_folder, z)\n",
    "        outpin = path.join(xtandem_folder, z.replace('.t.xml', '.pin'))\n",
    "        !tandem2pin $intf -P $decoy_prefix -o $outpin\n",
    "        outtarget = path.join(xtandem_folder, z.replace('.t.xml', '.target'))\n",
    "        outdecoy = path.join(xtandem_folder, z.replace('.t.xml', '.decoy'))\n",
    "        !percolator $outpin -U -m $outtarget -M $outdecoy\n",
    "        \n",
    "        outtarget2 = outtarget.replace('.target', '.target2')\n",
    "        out = open(outtarget2, 'w')\n",
    "        for x in open(outtarget):\n",
    "            out.write('\\t'.join(x.split('\\t')[:5]) + '\\t' + ';'.join(x.split('\\t')[5:]) + '\\n')\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for comet output\n",
    "\n",
    "perc_out = path.join(infolder, 'percolator_comet')\n",
    "if not path.isdir(perc_out):\n",
    "    mkdir(perc_out)\n",
    "\n",
    "for z in listdir(comet_folder):\n",
    "    if z.endswith('.target.pep.xml'):\n",
    "        inmgf = path.join(mgf_folder, z[::-1].split('_', 1)[-1][::-1] + '.mgf')\n",
    "        incomet = path.join(comet_folder, z)\n",
    "        fileroot = z.replace('.comet.target.pep.xml', '')\n",
    "        !crux percolator $incomet --decoy-prefix $decoy_prefix --output-dir $perc_out \\\n",
    "                        --fileroot $fileroot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for Identipy output\n",
    "\n",
    "identipy_folder = path.join(infolder, 'identipy')\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "for z in listdir(identipy_folder):\n",
    "    if z.endswith('.pep.xml'):\n",
    "        intf = path.join(identipy_folder, z)\n",
    "        !identipy2pin $intf\n",
    "        outtarget = path.join(identipy_folder, z.replace('.pep.xml', '.target'))\n",
    "        outdecoy = path.join(identipy_folder, z.replace('.pep.xml', '.decoy'))\n",
    "        outpin = path.join(identipy_folder, z.replace('.pep.xml', '.pin'))\n",
    "        !percolator $outpin -U -m $outtarget -M $outdecoy\n",
    "        \n",
    "        outtarget2 = outtarget.replace('.target', '.target2')\n",
    "        out = open(outtarget2, 'w')\n",
    "        for x in open(outtarget):\n",
    "            out.write('\\t'.join(x.split('\\t')[:5]) + '\\t' + ';'.join(x.split('\\t')[5:]) + '\\n')\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for MSFragger output\n",
    "\n",
    "msfragger_folder = path.join(infolder, 'msfragger')\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "for z in listdir(msfragger_folder):\n",
    "    if z.endswith('.pep.xml'):\n",
    "        intf = path.join(msfragger_folder, z)\n",
    "        !identipy2pin $intf\n",
    "        outtarget = path.join(msfragger_folder, z.replace('.pep.xml', '.target'))\n",
    "        outdecoy = path.join(msfragger_folder, z.replace('.pep.xml', '.decoy'))\n",
    "        outpin = path.join(msfragger_folder, z.replace('.pep.xml', '.pin'))\n",
    "        !percolator $outpin -U -m $outtarget -M $outdecoy\n",
    "        \n",
    "        outtarget2 = outtarget.replace('.target', '.target2')\n",
    "        out = open(outtarget2, 'w')\n",
    "        for x in open(outtarget):\n",
    "            out.write('\\t'.join(x.split('\\t')[:5]) + '\\t' + ';'.join(x.split('\\t')[5:]) + '\\n')\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Q-ranker for comet output\n",
    "mzxml_folder = path.join(infolder, 'mzxml')\n",
    "if not path.isdir(mzxml_folder):\n",
    "    mkdir(mzxml_folder)\n",
    "\n",
    "# Q-ranker require mzxml files. Please convert spectra files to mzxml format and put it to mzxml folder\n",
    "\n",
    "q_ranker_out = path.join(infolder, 'qranker')\n",
    "if not path.isdir(q_ranker_out):\n",
    "    mkdir(q_ranker_out)\n",
    "\n",
    "for z in listdir(comet_folder):\n",
    "    if z.endswith('.target.txt'):\n",
    "        inmgf = path.join(mzxml_folder, z[::-1].split('_', 1)[-1][::-1] + '.mzXML')# + '.mgf')\n",
    "        incomet = path.join(comet_folder, z)\n",
    "        fileroot = z.replace('.comet.target.txt', '')\n",
    "        !crux q-ranker $inmgf $incomet --decoy-prefix $decoy_prefix --output-dir $q_ranker_out \\\n",
    "                        --fileroot $fileroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN MPscore1 for MSFragger, X!Tandem and Identipy output\n",
    "# MPscore1 require file with parameters. Please, put file mpscore1.cfg to parameters folder.\n",
    "\n",
    "path_to_mpscore_1 = '/home/mark/work/PycharmProjects/mp-score/MPscore.py'\n",
    "\n",
    "params_folder = path.join(infolder, 'params')\n",
    "fasta_template = path_to_input_target_fasta.split('.fasta')[0] + '_shuffled_DECOY_%s.fasta'\n",
    "\n",
    "msfragger_mpscore1_folder = path.join(infolder, 'msfragger_mpscore1')\n",
    "if not path.isdir(msfragger_mpscore1_folder):\n",
    "    mkdir(msfragger_mpscore1_folder)\n",
    "for file in glob.glob(path.join(msfragger_folder, '*.pep.xml')):\n",
    "    shutil.copy(file, msfragger_mpscore1_folder)\n",
    "\n",
    "xtandem_mpscore1_folder = path.join(infolder, 'xtandem_mpscore1')\n",
    "if not path.isdir(xtandem_mpscore1_folder):\n",
    "    mkdir(xtandem_mpscore1_folder)\n",
    "for file in glob.glob(path.join(xtandem_folder, '*.pep.xml')):\n",
    "    shutil.copy(file, xtandem_mpscore1_folder)\n",
    "\n",
    "identipy_mpscore1_folder = path.join(infolder, 'identipy_mpscore1')\n",
    "if not path.isdir(identipy_mpscore1_folder):\n",
    "    mkdir(identipy_mpscore1_folder)\n",
    "for file in glob.glob(path.join(identipy_folder, '*.pep.xml')):\n",
    "    shutil.copy(file, identipy_mpscore1_folder)\n",
    "\n",
    "\n",
    "for ffolder in [\n",
    "    msfragger_mpscore1_folder,\n",
    "    xtandem_mpscore1_folder,\n",
    "    identipy_mpscore1_folder\n",
    "]:\n",
    "    for z in listdir(ffolder):\n",
    "        if z.endswith('.pep.xml'):\n",
    "            intf = path.join(ffolder, z)\n",
    "            basenum = z.split('.')[0].split('_')[-1]\n",
    "            infasta = fasta_template % (basenum, )\n",
    "            if 'confetti' in z:\n",
    "                inparams = path.join(params_folder, 'mpscore1_confetti.cfg')\n",
    "            else:\n",
    "                inparams = path.join(params_folder, 'mpscore1.cfg')\n",
    "\n",
    "            !python2 $path_to_mpscore_1 $intf $infasta $inparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine all results into dict\n",
    "\n",
    "# Please, put PeptideProphet output files to 4 folders below:\n",
    "\n",
    "prophet_comet_folder = path.join(infolder, 'prophet_comet')\n",
    "prophet_msgf_folder = path.join(infolder, 'prophet_msgf')\n",
    "prophet_fragger_folder = path.join(infolder, 'prophet_msfragger')\n",
    "prophet_tandem_folder = path.join(infolder, 'prophet_xtandem')\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "results_all = defaultdict(dict)\n",
    "\n",
    "# X!Tandem def\n",
    "def is_decoy_tandem(proteins):\n",
    "    return all(z.startswith(decoy_prefix) for z in proteins)\n",
    "\n",
    "def is_check_tandem(proteins):\n",
    "    return all(z.startswith('CHECK_') for z in proteins)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-D'\n",
    "    \n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            df00 = pepxml.DataFrame(path.join(xtandem_folder, z))\n",
    "            df00['decoy'] = df00['protein'].apply(is_decoy_tandem)\n",
    "            df00_f = aux.filter(df00, fdr=0.01, key='expect', is_decoy='decoy', correction=1, remove_decoy=True)\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['protein'].apply(is_check_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "\n",
    "# Comet def\n",
    "def is_decoy_tandem(proteins):\n",
    "    return all(z.startswith(decoy_prefix) for z in proteins)\n",
    "\n",
    "def is_check_tandem(proteins):\n",
    "    return all(z.startswith('CHECK_') for z in proteins)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-D'\n",
    "    \n",
    "    for z in listdir(comet_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            df00 = pepxml.DataFrame(path.join(comet_folder, z))\n",
    "            df00 = df00[~pd.isna(df00['peptide'])]\n",
    "            df00['decoy'] = df00['protein'].apply(is_decoy_tandem)\n",
    "            df00_f = aux.filter(df00, fdr=0.01, key='expect', is_decoy='decoy', correction=1, remove_decoy=True)\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['protein'].apply(is_check_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# MSFragger def\n",
    "def is_decoy_tandem(proteins):\n",
    "    return all(z.startswith(decoy_prefix) for z in proteins)\n",
    "\n",
    "def is_check_tandem(proteins):\n",
    "    return all(z.startswith('CHECK_') for z in proteins)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-D'\n",
    "    \n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            df00 = pepxml.DataFrame(path.join(msfragger_folder, z))\n",
    "            df00['decoy'] = df00['protein'].apply(is_decoy_tandem)\n",
    "            df00_f = aux.filter(df00, fdr=0.01, key='expect', is_decoy='decoy', correction=1, remove_decoy=True)\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['protein'].apply(is_check_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Identipy def\n",
    "def is_decoy_tandem(proteins):\n",
    "    return all(z.startswith(decoy_prefix) for z in proteins)\n",
    "\n",
    "def is_check_tandem(proteins):\n",
    "    return all(z.startswith('CHECK_') for z in proteins)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-D'\n",
    "    \n",
    "    for z in listdir(identipy_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            df00 = pepxml.DataFrame(path.join(identipy_folder, z))\n",
    "            df00['decoy'] = df00['protein'].apply(is_decoy_tandem)\n",
    "            df00_f = aux.filter(df00, fdr=0.01, key='expect', is_decoy='decoy', correction=1, remove_decoy=True)\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['protein'].apply(is_check_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# MSGF def\n",
    "def is_decoy_tandem(proteins):\n",
    "    return all(z.startswith(decoy_prefix) for z in proteins)\n",
    "\n",
    "def is_check_tandem(proteins):\n",
    "    return all(z.startswith('CHECK_') for z in proteins)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-D'\n",
    "    \n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('.mzid'):\n",
    "            df00 = mzid.DataFrame(path.join(msgf_folder, z))\n",
    "            df00['decoy'] = df00['protein description'].apply(is_decoy_tandem)\n",
    "            df00_f = aux.filter(df00, fdr=0.01, key='MS-GF:EValue', is_decoy='decoy', correction=1, remove_decoy=True)\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['protein description'].apply(is_check_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# # xtandem percolator\n",
    "\n",
    "def is_check_percolator_tandem(proteins):\n",
    "#     return 'CHECK_' in proteins\n",
    "    return all('CHECK_' in z for z in proteins.split(';'))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-P'\n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('.target2'):\n",
    "            df00 = pd.read_table(path.join(xtandem_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['proteinIds'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "# # msgf percolator\n",
    "\n",
    "def is_check_percolator_tandem(proteins):\n",
    "#     return 'CHECK_' in proteins\n",
    "    return all('CHECK_' in z for z in proteins.split(';'))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-P'\n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('.target2'):\n",
    "            df00 = pd.read_table(path.join(msgf_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['proteinIds'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "\n",
    "# MSFragger percolator\n",
    "\n",
    "def is_check_percolator_tandem(proteins):\n",
    "#     return 'CHECK_' in proteins\n",
    "    return all('CHECK_' in z for z in proteins.split(';'))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-P'\n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('.target2'):\n",
    "            df00 = pd.read_table(path.join(msfragger_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['proteinIds'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scavager MSFragger\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return all('CHECK_' in z for z in eval(proteins))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-M'\n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(msfragger_folder, z))\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['protein'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scavager msgf\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return all('CHECK_' in z for z in eval(proteins))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-M'\n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(msgf_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['protein'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scavager tandem\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return all('CHECK_' in z for z in eval(proteins))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-M'\n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(xtandem_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['protein'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scavager comet\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return all('CHECK_' in z for z in eval(proteins))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-M'\n",
    "    for z in listdir(comet_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(comet_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['protein'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "# # comet qranker\n",
    "\n",
    "def is_check_qranker(proteins):\n",
    "#     return proteins.startswith('CHECK_')\n",
    "    return all(z.startswith('CHECK_') for z in proteins.split(','))\n",
    "#     return 'CHECK_' in proteins\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-Q'\n",
    "    \n",
    "    for z in listdir(q_ranker_out):\n",
    "        if basic_name in z and z.endswith('.target.psms.txt'):\n",
    "            df1 = pd.read_table(path.join(q_ranker_out, z))\n",
    "            df1_t = df1[df1['q-ranker q-value'] <= 0.01][['protein id']]\n",
    "            tot = df1_t.shape[0]\n",
    "            dec = df1_t[df1_t['protein id'].apply(is_check_qranker)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "\n",
    "# # comet percolator\n",
    "\n",
    "def is_check_qranker(proteins):\n",
    "#     return proteins.startswith('CHECK_')\n",
    "    return all(z.startswith('CHECK_') for z in proteins.split(','))\n",
    "#     return 'CHECK_' in proteins\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-P'\n",
    "    \n",
    "    for z in listdir(perc_out):\n",
    "        if basic_name in z and z.endswith('percolator.target.psms.txt'):\n",
    "            df1 = pd.read_table(path.join(perc_out, z))\n",
    "            df1_t = df1[df1['percolator q-value'] <= 0.01][['protein id']]\n",
    "            tot = df1_t.shape[0]\n",
    "            dec = df1_t[df1_t['protein id'].apply(is_check_qranker)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "# # Identipy percolator\n",
    "\n",
    "def is_check_percolator_identipy(proteins):\n",
    "#     return 'CHECK_' in proteins\n",
    "    return all('CHECK_' in z for z in proteins.split(';'))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-P'\n",
    "    for z in listdir(identipy_folder):\n",
    "        if basic_name in z and z.endswith('.target2'):\n",
    "            df00 = pd.read_table(path.join(identipy_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['proteinIds'].apply(is_check_percolator_identipy)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scavager Identipy\n",
    "\n",
    "def is_check_mpscore_identipy(proteins):\n",
    "    return all('CHECK_' in z for z in eval(proteins))\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-M'\n",
    "    for z in listdir(identipy_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(identipy_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['protein'].apply(is_check_mpscore_identipy)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# # Prophet X!Tandem    \n",
    "    \n",
    "def is_check_prophet_tandem(proteins):\n",
    "    return all(z['protein'].startswith('CHECK_') for z in proteins['search_hit'][0]['proteins'])\n",
    "    \n",
    "def is_decoy_prophet_tandem(proteins):\n",
    "    return all(z['protein'].startswith('DECOY_') for z in proteins['search_hit'][0]['proteins'])\n",
    "\n",
    "score = lambda x: float(x['search_hit'][0]['analysis_result'][0]['peptideprophet_result']['probability'])\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-Pr'\n",
    "    \n",
    "    for z in listdir(prophet_tandem_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            \n",
    "            ids = [x for x in pepxml.read(path.join(prophet_tandem_folder, z))]\n",
    "            a_f = aux.filter(ids, fdr=0.01, key=score, is_decoy=is_decoy_prophet_tandem, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_tandem(z) for z in a_f)\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# # Prophet MSFragger   \n",
    "    \n",
    "def is_check_prophet_fragger(proteins):\n",
    "    return all(z['protein'].startswith('CHECK_') for z in proteins['search_hit'][0]['proteins'])\n",
    "    \n",
    "def is_decoy_prophet_fragger(proteins):\n",
    "    return all(z['protein'].startswith('DECOY_') for z in proteins['search_hit'][0]['proteins'])\n",
    "\n",
    "score = lambda x: float(x['search_hit'][0]['analysis_result'][0]['peptideprophet_result']['probability'])\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-Pr'\n",
    "    \n",
    "    for z in listdir(prophet_fragger_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            \n",
    "            ids = [x for x in pepxml.read(path.join(prophet_fragger_folder, z))]\n",
    "            a_f = aux.filter(ids, fdr=0.01, key=score, is_decoy=is_decoy_prophet_fragger, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_fragger(z) for z in a_f)\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# # Prophet comet   \n",
    "\n",
    "score = lambda x: float(x['search_hit'][0]['analysis_result'][0]['peptideprophet_result']['probability'])\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-Pr'\n",
    "    \n",
    "    for z in listdir(prophet_comet_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            \n",
    "            ids = [x for x in pepxml.read(path.join(prophet_comet_folder, z))]\n",
    "            a_f = aux.filter(ids, fdr=0.01, key=score, is_decoy=is_decoy_prophet_fragger, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_fragger(z) for z in a_f)\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# # Prophet msgf   \n",
    "\n",
    "score = lambda x: float(x['search_hit'][0]['analysis_result'][0]['peptideprophet_result']['probability'])\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-Pr'\n",
    "    \n",
    "    for z in listdir(prophet_msgf_folder):\n",
    "        if basic_name in z and z.endswith('.pep.xml'):\n",
    "            \n",
    "            ids = [x for x in pepxml.read(path.join(prophet_msgf_folder, z))]\n",
    "            a_f = aux.filter(ids, fdr=0.01, key=score, is_decoy=is_decoy_prophet_fragger, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_fragger(z) for z in a_f)\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "\n",
    "\n",
    "# MPscore1 X!Tandem\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return all('CHECK_' in z for z in proteins.split(';') if z)\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-M1'\n",
    "    for z in listdir(xtandem_mpscore1_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(xtandem_mpscore1_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['proteins'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# MPscore1 MSFragger\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-M1'\n",
    "    for z in listdir(msfragger_mpscore1_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(msfragger_mpscore1_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['proteins'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# MPscore1 IdentiPy\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-M1'\n",
    "    for z in listdir(identipy_mpscore1_folder):\n",
    "        if basic_name in z and z.endswith('_PSMs.tsv'):\n",
    "            df00 = pd.read_table(path.join(identipy_mpscore1_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['proteins'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all[basic_name][labelname] = dict()\n",
    "    results_all[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all[basic_name][labelname]['ids_std'] = np.std(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_map = {\n",
    "    'confetti_trypsin_01': 'Guo et al.',\n",
    "    '20100609_Velos1_TaGe_SA_293_4': 'Geiger et al.',\n",
    "    'olsen_100ng_30min_15k_01': 'Kelstrup et al.'\n",
    "}\n",
    "\n",
    "plt.figure(dpi=600)\n",
    "i = 0\n",
    "for dataset, workflows in results_all.items():\n",
    "    print(dataset)\n",
    "    for val_type in ['fdr',]:\n",
    "        X_labels = []\n",
    "        Y_vals = []\n",
    "        Y_std = []\n",
    "        for workflow, res in sorted(workflows.items()):\n",
    "            X_labels.append(workflow)\n",
    "            Y_vals.append(res['%s_mean' % (val_type, )] * 2)\n",
    "            Y_std.append(res['%s_std' % (val_type, )] * 2)\n",
    "        \n",
    "        if val_type == 'ids':\n",
    "            min_Y_vals = dict()\n",
    "            for lbl, val in zip(X_labels, Y_vals):\n",
    "                se = lbl.split('-')[0]\n",
    "                min_Y_vals[se] = min(min_Y_vals.get(se, 1e6), val)\n",
    "#             min_Y_val = min(Y_vals)\n",
    "            print(min_Y_vals)\n",
    "            Y_vals = [(x - min_Y_vals[lbl.split('-')[0]])/min_Y_vals[lbl.split('-')[0]]*100\n",
    "                      for x, lbl in zip(Y_vals, X_labels)]\n",
    "            Y_std = [0 for x in Y_std]\n",
    "            \n",
    "        X_array = np.array(range(len(X_labels)))\n",
    "        colors_dict = {\n",
    "            'C': 'y',\n",
    "            'X': 'b',\n",
    "            'I': 'g',\n",
    "            'M': 'k',\n",
    "            'F': 'm',\n",
    "        }\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        i += 1\n",
    "        if val_type == 'fdr':\n",
    "            plt.hlines(1.0, -0.17, X_array[-1] + 0.17, color='r')\n",
    "            plt.vlines(4.5, 0, 2.5, linestyles='--')\n",
    "            plt.vlines(9.5, 0, 2.5, linestyles='--')\n",
    "            plt.vlines(13.5, 0, 2.5, linestyles='--')\n",
    "            plt.vlines(17.5, 0, 2.5, linestyles='--')\n",
    "            plt.text(0.5, 1.7, 'Comet')\n",
    "            plt.text(5.5, 1.7, 'MSFragger')\n",
    "            plt.text(10.25, 1.7, 'IdentiPy')\n",
    "            plt.text(14.5, 1.7, 'MSGF+')\n",
    "            plt.text(18.25, 1.7, 'X!Tandem')\n",
    "        plt.bar(X_array, Y_vals, yerr=Y_std, width=0.33, color=[colors_dict[zz[0]] for zz in X_labels])\n",
    "        x_ticks_arr = [z.split('-')[-1] for z in X_labels]\n",
    "        x_ticks_arr = [zzz if zzz != 'M' else 'S' for zzz in x_ticks_arr]\n",
    "        x_ticks_arr = [zzz if zzz != 'M1' else 'M' for zzz in x_ticks_arr]\n",
    "#         print(x_ticks_arr)\n",
    "        plt.xticks(X_array, x_ticks_arr, size=10)\n",
    "        plt.yticks([0,1,2])\n",
    "        plt.ylim(0, 2.5)\n",
    "            \n",
    "        plt.ylabel('FDR, %')\n",
    "        plt.title(title_map.get(dataset), size=9)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN Percolator for X!Tandem output\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "fasta_template = path.join(fasta_folder, 'sprot_human_shuffled_DECOY_%s.fasta')\n",
    "\n",
    "mgf_folder = path.join(infolder, 'mzml')\n",
    "fasta_folder = path.join(infolder, 'fasta')\n",
    "\n",
    "xtandem_folder = path.join(infolder, 'xtandem')\n",
    "msgf_folder = path.join(infolder, 'msgf_mzml')\n",
    "identipy_folder = path.join(infolder, 'identipy')\n",
    "comet_folder = path.join(infolder, 'comet')\n",
    "msfragger_folder = path.join(infolder, 'msfragger')\n",
    "q_ranker_out = path.join(infolder, 'qranker')\n",
    "perc_out = path.join(infolder, 'percolator_comet')\n",
    "\n",
    "for ffolder in [\n",
    "    xtandem_folder,\n",
    "    identipy_folder,\n",
    "    msgf_folder,\n",
    "    msfragger_folder,\n",
    "]:\n",
    "    for z in listdir(ffolder):\n",
    "        if z.endswith('.pin'):\n",
    "            basenum = z.split('.')[0].split('_')[-1]\n",
    "            infasta = fasta_template % (basenum, )\n",
    "            intf = path.join(ffolder, z)\n",
    "            outpin = intf.replace('.pin', '.proteins_target')\n",
    "            !percolator $intf -A -l $outpin -P DECOY_ -f $infasta -r /dev/null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_out = path.join(infolder, 'percolator_comet_proteins')\n",
    "if not path.isdir(perc_out):\n",
    "    mkdir(perc_out)\n",
    "\n",
    "for z in listdir(comet_folder):\n",
    "    if z.endswith('.target.pep.xml'):\n",
    "        inmgf = path.join(mgf_folder, z[::-1].split('_', 1)[-1][::-1] + '.mgf')\n",
    "        incomet = path.join(comet_folder, z)\n",
    "        fileroot = z.replace('.comet.target.pep.xml', '')\n",
    "        !/home/mark/crux/bin/crux percolator $incomet --decoy-prefix $decoy_prefix --output-dir $perc_out \\\n",
    "                        --fileroot $fileroot --protein T --overwrite T --fido-empirical-protein-q T --protein-report-duplicates T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtandem_folder = path.join(infolder, 'xtandem')\n",
    "msgf_folder = path.join(infolder, 'msgf_mzml')\n",
    "identipy_folder = path.join(infolder, 'identipy')\n",
    "comet_folder = path.join(infolder, 'comet')\n",
    "msfragger_folder = path.join(infolder, 'msfragger')\n",
    "q_ranker_out = path.join(infolder, 'qranker')\n",
    "perc_out = path.join(infolder, 'percolator_comet_proteins')\n",
    "\n",
    "decoy_prefix = 'DECOY_'\n",
    "\n",
    "# combine all results into dict\n",
    "\n",
    "results_all_proteins = defaultdict(dict)\n",
    "\n",
    "# Scavager tandem\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return proteins.startswith('CHECK_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-M'\n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('_proteins.tsv'):\n",
    "            df00 = pd.read_table(path.join(xtandem_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['dbname'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "\n",
    "# Scavager msgf\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return proteins.startswith('CHECK_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-M'\n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('_proteins.tsv'):\n",
    "            df00 = pd.read_table(path.join(msgf_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['dbname'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "# Scaveger fragger\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return proteins.startswith('CHECK_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-M'\n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('_proteins.tsv'):\n",
    "            df00 = pd.read_table(path.join(msfragger_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['dbname'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "# Scavager identipy\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return proteins.startswith('CHECK_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-M'\n",
    "    for z in listdir(identipy_folder):\n",
    "        if basic_name in z and z.endswith('_proteins.tsv'):\n",
    "            df00 = pd.read_table(path.join(identipy_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['dbname'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "# Scavager comet\n",
    "\n",
    "def is_check_mpscore_tandem(proteins):\n",
    "    return proteins.startswith('CHECK_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-M'\n",
    "    for z in listdir(comet_folder):\n",
    "        if basic_name in z and z.endswith('_proteins.tsv'):\n",
    "            df00 = pd.read_table(path.join(comet_folder, z))\n",
    "#             df00 = df00[df00['length']>7]\n",
    "#             df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00.shape[0]\n",
    "            dec = df00[df00['dbname'].apply(is_check_mpscore_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "            \n",
    "# # Prophet X!Tandem    \n",
    "    \n",
    "prophet_tandem_folder = path.join(infolder, 'prophet_xtandem')\n",
    "prophet_comet_folder = path.join(infolder, 'prophet_comet')\n",
    "prophet_fragger_folder = path.join(infolder, 'prophet_msfragger')\n",
    "prophet_msgf_folder = path.join(infolder, 'prophet_msgf')\n",
    "\n",
    "def is_check_prophet_tandem(proteins):\n",
    "    return proteins['protein_name'].str.startswith('CHECK_')\n",
    "    \n",
    "def is_decoy_prophet_tandem(proteins):\n",
    "    return proteins['protein_name'].startswith('DECOY_')\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "#     basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-Pr'\n",
    "    \n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('.prot.xml'):\n",
    "#             print(z)\n",
    "            \n",
    "            ids = protxml.DataFrame(path.join(xtandem_folder, z))\n",
    "            a_f = aux.filter(ids, fdr=0.01, key='confidence', is_decoy=is_decoy_prophet_tandem, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_tandem(a_f))\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    basic_name = basic_name.split('teract-')[-1]\n",
    "#     print('OK')\n",
    "#     print(fdrs_list)\n",
    "#     print(ids_list)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "#     basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-Pr'\n",
    "    \n",
    "    for z in listdir(comet_folder):\n",
    "        if basic_name in z and z.endswith('.prot.xml'):\n",
    "#             print(z)\n",
    "            \n",
    "            ids = protxml.DataFrame(path.join(comet_folder, z))\n",
    "            a_f = aux.filter(ids, fdr=0.01, key='confidence', is_decoy=is_decoy_prophet_tandem, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_tandem(a_f))\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    basic_name = basic_name.split('teract-')[-1]\n",
    "#     print('OK')\n",
    "#     print(fdrs_list)\n",
    "#     print(ids_list)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "#     basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-Pr'\n",
    "    \n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('.prot.xml'):\n",
    "#             print(z)\n",
    "            \n",
    "            ids = protxml.DataFrame(path.join(msfragger_folder, z))\n",
    "            a_f = aux.filter(ids, fdr=0.01, key='confidence', is_decoy=is_decoy_prophet_tandem, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_tandem(a_f))\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    basic_name = basic_name.split('teract-')[-1]\n",
    "#     print('OK')\n",
    "#     print(fdrs_list)\n",
    "#     print(ids_list)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "#     basic_name = basic_name.lower()\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-Pr'\n",
    "    \n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('.prot.xml'):\n",
    "#             print(z)\n",
    "            \n",
    "            ids = protxml.DataFrame(path.join(msgf_folder, z))\n",
    "            a_f = aux.filter(ids, fdr=0.01, key='confidence', is_decoy=is_decoy_prophet_tandem, reverse=True, remove_decoy=True, correction=1, formula=1)\n",
    "            tot = len(a_f)\n",
    "            dec = sum(is_check_prophet_tandem(a_f))\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    if basic_name == '20100609_velos1_tage_sa_293_4':\n",
    "        basic_name = '20100609_Velos1_TaGe_SA_293_4'\n",
    "    basic_name = basic_name.split('teract-')[-1]\n",
    "#     print('OK')\n",
    "#     print(fdrs_list)\n",
    "#     print(ids_list)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # X!Tandem percolator\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'X-P'\n",
    "    for z in listdir(xtandem_folder):\n",
    "        if basic_name in z and z.endswith('.proteins_target'):\n",
    "            df00 = pd.read_table(path.join(xtandem_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['ProteinId'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # msgf percolator\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'M-P'\n",
    "    for z in listdir(msgf_folder):\n",
    "        if basic_name in z and z.endswith('.proteins_target'):\n",
    "            df00 = pd.read_table(path.join(msgf_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['ProteinId'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # Comet percolator\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'C-P'\n",
    "    for z in listdir(perc_out):\n",
    "        if basic_name in z and z.endswith('.percolator.target.proteins.txt'):\n",
    "            df00 = pd.read_table(path.join(perc_out, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['ProteinId'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    \n",
    "   \n",
    "# Identipy percolator\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'I-P'\n",
    "    for z in listdir(identipy_folder):\n",
    "        if basic_name in z and z.endswith('.proteins_target'):\n",
    "            df00 = pd.read_table(path.join(identipy_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['ProteinId'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "\n",
    "    \n",
    "# # MSFragger percolator\n",
    "\n",
    "for mgffile in listdir(mgf_folder):\n",
    "    basic_name = path.splitext(mgffile)[0]\n",
    "    \n",
    "    fdrs_list = []\n",
    "    ids_list = []\n",
    "    labelname = 'F-P'\n",
    "    for z in listdir(msfragger_folder):\n",
    "        if basic_name in z and z.endswith('.proteins_target'):\n",
    "            df00 = pd.read_table(path.join(msfragger_folder, z))\n",
    "            df00_f = df00[df00['q-value'] <= 0.01]\n",
    "            tot = df00_f.shape[0]\n",
    "            dec = df00_f[df00_f['ProteinId'].apply(is_check_percolator_tandem)].shape[0]\n",
    "            fdrs_list.append(dec * 100 / tot)\n",
    "            ids_list.append(tot)\n",
    "    print(labelname, basic_name, len(fdrs_list), np.mean(ids_list), np.std(ids_list), np.mean(fdrs_list), np.std(fdrs_list))\n",
    "    results_all_proteins[basic_name][labelname] = dict()\n",
    "    results_all_proteins[basic_name][labelname]['fdr_mean'] = np.mean(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_mean'] = np.mean(ids_list)\n",
    "    results_all_proteins[basic_name][labelname]['fdr_std'] = np.std(fdrs_list)\n",
    "    results_all_proteins[basic_name][labelname]['ids_std'] = np.std(ids_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=600)\n",
    "i = 0\n",
    "for dataset, workflows in results_all_proteins.items():\n",
    "    print(dataset)\n",
    "    for val_type in ['fdr',]:#, 'ids']:\n",
    "        X_labels = []\n",
    "        Y_vals = []\n",
    "        Y_std = []\n",
    "        for workflow, res in sorted(workflows.items()):\n",
    "            X_labels.append(workflow)\n",
    "            Y_vals.append(res['%s_mean' % (val_type, )] * 2)\n",
    "            Y_std.append(res['%s_std' % (val_type, )] * 2)\n",
    "        \n",
    "        if val_type == 'ids':\n",
    "            min_Y_vals = dict()\n",
    "            for lbl, val in zip(X_labels, Y_vals):\n",
    "                se = lbl.split('-')[0]\n",
    "                min_Y_vals[se] = min(min_Y_vals.get(se, 1e6), val)\n",
    "#             min_Y_val = min(Y_vals)\n",
    "            print(min_Y_vals)\n",
    "            Y_vals = [(x - min_Y_vals[lbl.split('-')[0]])/min_Y_vals[lbl.split('-')[0]]*100\n",
    "                      for x, lbl in zip(Y_vals, X_labels)]\n",
    "            Y_std = [0 for x in Y_std]\n",
    "            \n",
    "        X_array = np.array(range(len(X_labels)))\n",
    "        colors_dict = {\n",
    "            'C': 'y',\n",
    "            'X': 'b',\n",
    "            'I': 'g',\n",
    "            'M': 'k',\n",
    "            'F': 'm',\n",
    "        }\n",
    "        plt.subplot(3, 1, i+1)\n",
    "        i += 1\n",
    "        if val_type == 'fdr':\n",
    "            plt.hlines(1.0, -0.17, X_array[-1] + 0.17, color='r')\n",
    "        plt.bar(X_array, Y_vals, yerr=Y_std, width=0.33, color=[colors_dict[zz[0]] for zz in X_labels])\n",
    "        x_ticks_arr = [z.split('-')[-1] for z in X_labels]\n",
    "        x_ticks_arr = [zzz if zzz != 'M' else 'S' for zzz in x_ticks_arr]\n",
    "        x_ticks_arr = [zzz if zzz != 'M1' else 'M' for zzz in x_ticks_arr]\n",
    "#         print(x_ticks_arr)\n",
    "        plt.xticks(X_array, x_ticks_arr, size=10)\n",
    "        if i == 1:\n",
    "            plt.ylim(0, 3)\n",
    "            \n",
    "            \n",
    "            legend_elements1 = [\n",
    "                Patch(facecolor='xkcd:dirty yellow', edgecolor='y',\n",
    "                         label='Color Patch'),  \n",
    "                \n",
    "                Patch(facecolor='xkcd:pinkish purple', edgecolor='m',\n",
    "                         label='Color Patch'), \n",
    "            ]\n",
    "            legend_elements2 = [\n",
    "                Patch(facecolor='green', edgecolor='g',\n",
    "                         label='Color Patch'), \n",
    "                plt.hlines(1.0, -0.17, X_array[-1] + 0.17, color='r')\n",
    "            ]\n",
    "            \n",
    "            legend_elements3 = [\n",
    "                Patch(facecolor='black', edgecolor='k',\n",
    "                         label='Color Patch'), \n",
    "                Patch(facecolor='blue', edgecolor='b',\n",
    "                         label='Color Patch'), \n",
    "                              ]\n",
    "\n",
    "            legend_names1 = ['Comet', 'MSFragger']\n",
    "            legend_names2 = ['IdentiPy', 'expected FDR']\n",
    "            legend_names3 = ['MSGF+', 'X!Tandem']\n",
    "#             # Create the figure\n",
    "#             fig, ax = plt.subplots()\n",
    "#             ax.legend(handles=legend_elements, loc='center')\n",
    "            legend1 = plt.legend(legend_elements1, legend_names1, loc=2, prop={'size': 8})\n",
    "            legend2 = plt.legend(legend_elements2, legend_names2, loc=9, prop={'size': 8})\n",
    "#             pyplot.legend([l[0] for l in plot_lines], parameters, loc=4)\n",
    "            plt.legend(legend_elements3, legend_names3, loc=1, prop={'size': 8})\n",
    "            plt.gca().add_artist(legend1)\n",
    "            plt.gca().add_artist(legend2)\n",
    "#             plt.legend(legend_elements, loc=2)\n",
    "        plt.ylabel('real FDR, %')\n",
    "        plt.title(title_map.get(dataset), size=9)\n",
    "        plt.tight_layout()\n",
    "#             pylab.bar(xrang, np.array(ms2h) - np.array(ms2h_single_peptide), width=0.33, edgecolor='black', color='#6495ED', hatch=\"//\\\\\\\\\")\n",
    "#             pylab.bar(xrang + 0.33, ms1h, yerr=errs, width=0.33, color='r')\n",
    "#         break\n",
    "        \n",
    "        \n",
    "#     break\n",
    "# plt.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
